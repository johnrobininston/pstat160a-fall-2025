---
title: ""
author: ""
format:
  pdf:
    pdf-engine: xelatex   # or lualatex
    geometry: margin=1in
header-includes:
  - \usepackage{amsmath,amssymb,amsfonts}
  - \usepackage{enumitem}
  - \setlist[enumerate,1]{label=(\alph*)}
  - \usepackage{libertinus}    % text/math font family
---

\LARGE\textbf{PSTAT160A Stochastic Processes}\vspace{5pt}\newline
\Large\textbf{Section 4 - Solutions}\vspace{5pt} \newline
\normalsize\textbf{Authors:} \textit{Denisse Alejandra Escobar Parra, John Inston} \newline
\textbf{Date:} \textit{October 21, 2025}\newline
\hrule

## Problem 1 - Dobrow Q2.1

A Markov chain has transition matrix
$$
P:=\begin{bmatrix}
0.1 & 0.3 & 0.6 \\
0 & 0.4 & 0.6 \\
0.3 & 0.2 & 0.5
\end{bmatrix},
$$

with initial distribution $\alpha=\begin{bmatrix}0.2 & 0.3 & 0.5\end{bmatrix}$.  Find the following:

1. $\mathbb{P}(X_{7}=3|X_{6}=2)$,
2. $\mathbb{P}(X_{9}=2|X_{1}=2,X_{5}=1, X_{7}=3)$,
3. $\mathbb{P}(X_{0}|X_{1}=1)$,
4. $\mathbb{E}[X_{2}]$.

### Solution

1. From time invariance, directly from the transition probability matrix we have $$\mathbb{P}(X_{7}=3|X_{6}=2)=0.6.$$
2. The two-step transition probability matrix can be computed using R / python as $$P^2=\begin{bmatrix}0.19 & 0.27 & 0.54 \\ 0.18 & 0.28 & 0.54 \\ 0.18 & 0.27 & 0.55\end{bmatrix}.$$ From the Markov (memoryless) property we have that $$\begin{aligned}\mathbb{P}(X_{9}=2|X_{7}=3, X_{5}=1, X_{1}=2)  & = \mathbb{P}(X_{9}=2|X_{7}=3) \\ & =0.27.\end{aligned}$$
3. From Bayes Theorem we can compute $$\begin{aligned}\mathbb{P}(X_{0}|X_{1}=1) & \propto \mathbb{P}(X_{1}=1|X_{0}=x)\mathbb{P}(X_{0}=x) \\ & \propto \begin{bmatrix}0.1  \\ 0  \\ 0.3\end{bmatrix}\cdot \begin{bmatrix}0.2 \\ 0.3 \\ 0.5 \end{bmatrix} \\ & \propto \begin{bmatrix}0.02 \\ 0 \\ 0.15 \end{bmatrix}.\end{aligned}$$ To find the constant of proportionality we note that $$\begin{aligned}c(0.02+0.15) & = c\cdot\frac{17}{100} = 1 \\ \implies c & = \frac{100}{17}.\end{aligned}$$ Thus the mass function is given by $$\mathbb{P}(X_{0}=x|X_{1}=1)=\begin{cases} \frac{2}{17} & x=1, \\ 0 & x=2, \\ \frac{15}{17} & x=3.\end{cases}$$
4. First we compute using R / python as $$\begin{aligned}\mathbb{P}(X_{2}) & = P^2\alpha = \begin{bmatrix}0.182  \\0.273  \\ 0.545 \end{bmatrix}\end{aligned}.$$ Then to compute the expectation we write $$\begin{aligned}\mathbb{E}[X_{2}] & =\sum_{x=1}^{3}x \cdot \mathbb{P}(X_{2}=2) \\& = 0.182 + 2(0.273) + 3(0.545) \\ & = 2.363.\end{aligned}$$

## Problem 2 - Dobrow Q2.2

Let $X_{0}, X_{1}, \dots$ be a Markov chain with transition matrix
$$
P=\begin{bmatrix}
0 & \frac{1}{2} & \frac{1}{2} \\
1 & 0 & 0  \\
\frac{1}{3} & \frac{1}{3} & \frac{1}{3}
\end{bmatrix},
$$

and initial distribution $\alpha=\begin{bmatrix} \frac{1}{2} & 0 & \frac{1}{2}\end{bmatrix}$.  Find the following:

1. $\mathbb{P}(X_{2}=1|X_{1}=3)$,
2. $\mathbb{P}(X_{1}=3,X_{2}=1)$,
3. $\mathbb{P}(X_{1}=3|X_{2}=1)$,
4. $\mathbb{P}(X_{9}=1|X_{1}=3, X_{4}=1, X_{7}=2)$.

### Solution

1. From time invariance, directly from the transition probability matrix we have $$\mathbb{P}(X_{2}=1|X_{1}=3) = \frac{1}{3}.$$
2. We first compute using R / python $$\begin{aligned}\mathbb{P}(X_{1}) & = \mathbb{P}(X_{1}|X_{0})\cdot \mathbb{P}(X_{0}) \\ & = P \cdot \alpha \\ & = \begin{bmatrix} \frac{1}{6} \\ \frac{5}{12} \\ \frac{5}{12}\end{bmatrix}.\end{aligned}$$ From this we can apply the definition of conditional probability $$\begin{aligned} \mathbb{P}(X_{2}=1,X_{1}=3) & = \mathbb{P}(X_{2}=1|X_{1}=3)\cdot \mathbb{P}(X_{1}=3) \\ & = \frac{1}{3}\cdot \frac{5}{12} \\ & = \frac{5}{36}.\end{aligned}$$
3. We compute using R / python $$\begin{aligned}\mathbb{P}(X_{2}) & = P^2 \alpha \\ & = \begin{bmatrix}\frac{5}{9} \\ \frac{2}{9} \\ \frac{2}{9}\end{bmatrix}.\end{aligned}$$ We can then compute from the definition of conditional probability $$\begin{aligned} \mathbb{P}(X_{1}=3|X_{2}=1) & = \frac{\mathbb{P}(X_{1}=3,X_{2}=1)}{\mathbb{P}(X_{2}=1)} \\ & = \frac{5}{36} \cdot \frac{9}{5} \\ & = \frac{9}{36} = \frac{1}{4}.\end{aligned}$$
4. Using R / python we can compute $$\begin{aligned}\mathbb{P}(X_{2}) & = P^2 \\ & = \begin{bmatrix}
\frac{2}{3} & \frac{1}{6} & \frac{1}{6} \\ 0 & \frac{1}{2} & \frac{1}{2} \\ \frac{4}{9} & \frac{5}{18} & \frac{5}{18} \end{bmatrix}.\end{aligned}$$ We can then compute using th Markov property and time invariance $$ \begin{aligned} \mathbb{P}(X_{9}=1|X_{1}=3,X_{4}=1,X_{7}=3) & = \mathbb{P}(X_{9}=1|X_{7}=2) \\ & = \mathbb{P}(X_{2}=1|X_{0}=2) \\ & = 0.\end{aligned}$$

## Problem 3 - Dobrow Q2.4

For the general two-state chain with transition matrix
$$
P=\begin{bmatrix}
1-p & p \\
q & 1-q
\end{bmatrix},
$$

and initial distribution $\alpha=\begin{bmatrix}\alpha_{1} & \alpha_{2}\end{bmatrix}$ find the following:

1. the two-step transition matrix
2. the distribution $X_{1}$.

### Solution

1. We can compute $$\begin{aligned}P^2 & = \begin{bmatrix} 1-p & p \\ q & 1-q \end{bmatrix} \cdot \begin{bmatrix} 1-p & p \\ q & 1-q \end{bmatrix} \\ & = \begin{bmatrix} (1-p)^2 + pq & p(1-p)+p(1-q)  \\ q(1-p) + q(1-q) & pq+(1-q)^2 \end{bmatrix} \\ & = \begin{bmatrix} (1-p)^2 + pq & p(2-p-q)  \\ q(2-p-q) & pq+(1-q)^2 \end{bmatrix} \end{aligned}.$$
2. We can compute $$\begin{aligned}\mathbb{P}(X_{1}) & = \mathbb{P}(X_{1}|X_{0})\cdot \mathbb{P}(X_{0}) \\
 & = \begin{bmatrix} 1-p & p \\ q & 1-q \end{bmatrix} \begin{bmatrix} \alpha_{1} \\ \alpha_{2} \end{bmatrix} \\ & = \begin{bmatrix} \alpha_{1}(1-p)+p\alpha_{2}  \\ q\alpha_{1}+\alpha_{2}(1-q) \end{bmatrix}. \end{aligned}$$

## Problem 4 - Dobrow Q2.6

A tetrahedron die has four faces labelled 1, 2, 3 and 4.  In repeated independent rolls of the die $R_{0}, R_{1}, \dots$, let $X_{n}=\max(R_{0}, \dots, R_{n})$ be the maximum value after $n+1$ rolls, for $n \geq 0$:

1. Give an intuitive argument for why $X_{0}, X_{1}, \dots$ is a Markov chain, and exhibit the transition matrix.
2. Find $\mathbb{P}(X_{3}\geq 3)$.

### Solution

1. Intuitively we have a finite state chain with $\mathcal{S}:=\{ 1,2,3,4 \}$ with transition probability matrix $$P:=\begin{bmatrix} \frac{1}{4} & \frac{1}{4} & \frac{1}{4} & \frac{1}{4} \\ 0 & \frac{1}{2}  & \frac{1}{4} & \frac{1}{4} \\ 0 & 0 & \frac{3}{4} & \frac{1}{4} \\ 0 & 0 & 0 & 1 \end{bmatrix};\quad \alpha=\begin{bmatrix} \frac{1}{4} \\ \frac{1}{4} \\ \frac{1}{4} \\ \frac{1}{4} \end{bmatrix}.$$ The chain is Markov because given the current state of the chain we do not gain information about the distribution of the next state from knowing the history.
2. We can quickly compute $$\begin{aligned} \mathbb{P}(X_{3}\geq 3) & = 1-\mathbb{P}(X_{3}\leq 2) \\ & = 1-\left(  \frac{2}{4} \right)^4 \\ & = \frac{15}{16}.\end{aligned}$$

## Problem 5 - Dobrow Q2.7 

Let $X_{0}, X_{1}, \dots$ be a Markov chain with transition matrix $P$.  Let $Y_{n}=X_{3n}$, for $n=0,1,2,\dots$.  Show that $Y_{0}, Y_{1}, \dots$ is a Markov chain and exhibit its transition matrix.

### Solution

*PROOF:*
From the Markov property
$$
\begin{aligned}
\mathbb{P}(Y_{n+1}|Y_{0}, \dots, Y_{n}) & = \mathbb{P}(X_{3n+3}|X_{0}, \dots, X_{3n}) \\
 & = \mathbb{P}(X_{3n+3}|X_{3n}) \\
 & = \mathbb{P}(Y_{n+1}|Y_{n}).
\end{aligned}
$$
$\square$


